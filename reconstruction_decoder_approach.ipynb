{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sunsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchinfo import summary         \n",
    "import numpy as np\n",
    "import torchvision.transforms as tf\n",
    "import transformers                    \n",
    "from tensorboardX import SummaryWriter \n",
    "from pkg_resources import packaging    \n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from openTSNE import TSNE              \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2023\n",
    "random.seed(seed)  \n",
    "np.random.seed(seed)  \n",
    "torch.manual_seed(seed) \n",
    "torch.cuda.manual_seed(seed)  \n",
    "torch.cuda.manual_seed_all(seed) \n",
    "torch.backends.cudnn.benchmark = False  \n",
    "torch.backends.cudnn.deterministic = True  \n",
    "\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os,sys,humanize,psutil,GPUtil\n",
    "\n",
    "# Define function\n",
    "def mem_report():\n",
    "  print(\"CPU RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ))\n",
    "  \n",
    "  GPUs = GPUtil.getGPUs()\n",
    "  for i, gpu in enumerate(GPUs):\n",
    "    print('GPU {:d} ... Mem Free: {:.0f}MB / {:.0f}MB | Utilization {:3.0f}%'.format(i, gpu.memoryFree, gpu.memoryTotal, gpu.memoryUtil*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_set = torchvision.datasets.CIFAR10(\"./data\", train=True, download=True)\n",
    "test_set = torchvision.datasets.CIFAR10(\"./data\", train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_model = torch.load('model_classification_resnet50.pth')\n",
    "latent_code_model = torch.load('model_classification_resnet50_withoutfc.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "skip to next empty markdown cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple_tf = tf.Compose([\n",
    "#     tf.PILToTensor(),\n",
    "#     tf.ConvertImageDtype(torch.float),\n",
    "#     tf.Resize((224, 224)),#, interpolation=torchvision.transforms.InterpolationMode.BICUBIC),\n",
    "#     tf.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "# ])\n",
    "\n",
    "# train_tf = tf.Compose([\n",
    "#     tf.PILToTensor(),\n",
    "#     tf.ConvertImageDtype(torch.float),\n",
    "#     tf.RandomHorizontalFlip(),\n",
    "#     tf.Resize((224, 224)),#, interpolation=torchvision.transforms.InterpolationMode.BICUBIC),\n",
    "#     # tf.RandomErasing(),\n",
    "#     tf.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set = torchvision.datasets.CIFAR10(\"./data\", train=True, download=False, transform=train_tf)\n",
    "# test_set = torchvision.datasets.CIFAR10(\"./data\", train=False, download=False, transform=simple_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataloader_classification = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=False)\n",
    "# test_dataloader_classification = torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_data(model, loader, latent_size=2048):\n",
    "#     data_tensor = torch.zeros((0, latent_size))#.to(device)\n",
    "#     # label_tensor = torch.zeros((0, 1), dtype=torch.int32)#.to(device)\n",
    "#     # images_tensor = torch.zeros((0, 3, image_size, image_size), dtype=torch.int32)#.to(device)\n",
    "#     with torch.no_grad():\n",
    "#         for images, labels in loader:\n",
    "#             # images = images.to(device)\n",
    "#             # labels = labels.to(device).reshape(-1, 1)\n",
    "#             # images = images\n",
    "#             # labels = labels.reshape(-1, 1)\n",
    "#             output = model(images.to(device)).squeeze().cpu()\n",
    "#             data_tensor = torch.vstack([data_tensor, output])\n",
    "#             # label_tensor = torch.vstack([label_tensor, labels])\n",
    "#             # images_tensor = torch.vstack([images_tensor, images])\n",
    "#             # print('-')\n",
    "\n",
    "#     # feature_dataset = torch.utils.data.TensorDataset(data_tensor, images_tensor, label_tensor)\n",
    "#     # feature_loader = torch.utils.data.DataLoader(feature_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "#     return data_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataloader_decoder = extract_data(latent_code_model, train_dataloader_classification)\n",
    "# test_dataloader_decoder = extract_data(latent_code_model, test_dataloader_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Specify the file path where you want to save the tensor\n",
    "# train_dataloader_decoder_path = 'train_data_latent.pth'\n",
    "# test_dataloader_decoder_path = 'test_data_latent.pth'\n",
    "\n",
    "# # Save the tensor to the specified file path\n",
    "# torch.save(train_dataloader_decoder, train_dataloader_decoder_path)\n",
    "# torch.save(test_dataloader_decoder, test_dataloader_decoder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_latent_coords = torch.load('train_data_latent.pth')\n",
    "test_set_latent_coords = torch.load('test_data_latent.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_tf = tf.Compose([\n",
    "    tf.PILToTensor(),\n",
    "    tf.ConvertImageDtype(torch.float),\n",
    "    # tf.Resize((224, 224)),#, interpolation=torchvision.transforms.InterpolationMode.BICUBIC),\n",
    "    # tf.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "train_tf = tf.Compose([\n",
    "    tf.PILToTensor(),\n",
    "    tf.ConvertImageDtype(torch.float),\n",
    "    tf.RandomHorizontalFlip(),\n",
    "    # tf.Resize((224, 224)),#, interpolation=torchvision.transforms.InterpolationMode.BICUBIC),\n",
    "    # tf.RandomErasing(),\n",
    "    # tf.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.CIFAR10(\"./data\", train=True, download=False, transform=train_tf)\n",
    "test_set = torchvision.datasets.CIFAR10(\"./data\", train=False, download=False, transform=simple_tf)\n",
    "\n",
    "train_dataloader_classification = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=False)\n",
    "test_dataloader_classification = torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_shape=(2048,)):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        # Decoder blocks\n",
    "        self.decoder_blocks = nn.Sequential(\n",
    "            self._make_decoder_block(128, 512),\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            self._make_decoder_block(512, 256),\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            self._make_decoder_block(256, 256),\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            self._make_decoder_block(256, 256)\n",
    "        )\n",
    "        \n",
    "        # Final convolution layer\n",
    "        self.final_conv = nn.Sequential(\n",
    "            nn.Conv2d(256, 3, kernel_size=3, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def _make_decoder_block(self, pre_filters, filters):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(pre_filters, filters, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(0.3),\n",
    "            nn.BatchNorm2d(filters),\n",
    "            nn.ConvTranspose2d(filters, filters, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(0.3),\n",
    "            nn.BatchNorm2d(filters),\n",
    "            nn.ConvTranspose2d(filters, filters, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(0.3),\n",
    "            nn.BatchNorm2d(filters),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), 128, 4, 4)\n",
    "        x = self.decoder_blocks(x)\n",
    "        x = self.final_conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ZipDataset(Dataset):\n",
    "    def __init__(self, original_dataset, latent_coords):\n",
    "        self.original_dataset = original_dataset\n",
    "        self.latent_coords = latent_coords\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.original_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.original_dataset[idx]\n",
    "        latent_coord = self.latent_coords[idx]\n",
    "\n",
    "        return image, latent_coord, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloaders, optimizer, **kwargs):\n",
    "    train_loader, test_loader = dataloaders\n",
    "    device = kwargs['device']\n",
    "    loss = nn.MSELoss().to(device)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    for epoch in range(kwargs['max_epochs']):\n",
    "        ########  Train  ########\n",
    "        loss_list = []\n",
    "        model.train()\n",
    "        last_time = time.time()\n",
    "        for local_step, (images, latent_coords, labels) in enumerate(train_loader):\n",
    "            step = epoch * len(train_loader) + local_step\n",
    "            images, latent_coords, labels = images.to(device), latent_coords.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(latent_coords)\n",
    "            # print(torch.max(outputs), torch.min(outputs))\n",
    "            # print(outputs.shape)\n",
    "            l = loss(outputs, images)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # log\n",
    "            loss_list.append(l.detach().cpu().item())\n",
    "            if (local_step % 100 == 0 and local_step != 0) or local_step == len(train_loader) - 1:\n",
    "                print(\"Epoch {}/{} | Step {}/{} | loss:{:.5f} time: {:.1f}s\".format(\n",
    "                    epoch, kwargs['max_epochs'], local_step, len(train_loader),\n",
    "                    sum(loss_list)/len(loss_list),\n",
    "                    time.time() - last_time\n",
    "                ))\n",
    "                last_time = time.time()\n",
    "        ########  Test  ########\n",
    "        loss_list = []\n",
    "        print(\"-\"*20 + \"   Testing   \" + \"-\"*20)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for local_step, (images, latent_coords, labels) in enumerate(test_loader):\n",
    "                images, latent_coords, labels = images.to(device), latent_coords.to(device), labels.to(device)\n",
    "                outputs = model(latent_coords)\n",
    "                l = loss(outputs, images)\n",
    "                loss_list.append(l.cpu().item())\n",
    "            # log\n",
    "            print(\"Epoch {}/{} | loss:{:.5f}\".format(\n",
    "                epoch, kwargs['max_epochs'],\n",
    "                sum(loss_list)/len(loss_list)\n",
    "            ))\n",
    "        print(\"=\" * 53)\n",
    "        mem_report()\n",
    "        print(\"=\" * 53)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/20 | Step 100/782 | loss:0.05997 time: 13.4s\n",
      "Epoch 0/20 | Step 200/782 | loss:0.05425 time: 10.2s\n",
      "Epoch 0/20 | Step 300/782 | loss:0.05078 time: 10.1s\n",
      "Epoch 0/20 | Step 400/782 | loss:0.04876 time: 10.1s\n",
      "Epoch 0/20 | Step 500/782 | loss:0.04726 time: 10.0s\n",
      "Epoch 0/20 | Step 600/782 | loss:0.04613 time: 10.0s\n",
      "Epoch 0/20 | Step 700/782 | loss:0.04524 time: 9.9s\n",
      "Epoch 0/20 | Step 781/782 | loss:0.04465 time: 8.0s\n",
      "--------------------   Testing   --------------------\n",
      "Epoch 0/20 | loss:0.04031\n",
      "=====================================================\n",
      "CPU RAM Free: 1.4 GB\n",
      "GPU 0 ... Mem Free: 3386MB / 8192MB | Utilization  57%\n",
      "=====================================================\n",
      "Epoch 1/20 | Step 100/782 | loss:0.03891 time: 10.0s\n",
      "Epoch 1/20 | Step 200/782 | loss:0.03855 time: 9.9s\n",
      "Epoch 1/20 | Step 300/782 | loss:0.03840 time: 9.9s\n",
      "Epoch 1/20 | Step 400/782 | loss:0.03835 time: 9.8s\n",
      "Epoch 1/20 | Step 500/782 | loss:0.03811 time: 9.8s\n",
      "Epoch 1/20 | Step 600/782 | loss:0.03787 time: 9.9s\n",
      "Epoch 1/20 | Step 700/782 | loss:0.03773 time: 9.9s\n",
      "Epoch 1/20 | Step 781/782 | loss:0.03759 time: 7.9s\n",
      "--------------------   Testing   --------------------\n",
      "Epoch 1/20 | loss:0.03647\n",
      "=====================================================\n",
      "CPU RAM Free: 1.4 GB\n",
      "GPU 0 ... Mem Free: 3386MB / 8192MB | Utilization  57%\n",
      "=====================================================\n",
      "Epoch 2/20 | Step 100/782 | loss:0.03605 time: 10.0s\n",
      "Epoch 2/20 | Step 200/782 | loss:0.03602 time: 9.9s\n",
      "Epoch 2/20 | Step 300/782 | loss:0.03592 time: 9.8s\n",
      "Epoch 2/20 | Step 400/782 | loss:0.03586 time: 9.8s\n",
      "Epoch 2/20 | Step 500/782 | loss:0.03573 time: 9.8s\n",
      "Epoch 2/20 | Step 600/782 | loss:0.03573 time: 9.8s\n",
      "Epoch 2/20 | Step 700/782 | loss:0.03575 time: 9.8s\n",
      "Epoch 2/20 | Step 781/782 | loss:0.03569 time: 7.9s\n",
      "--------------------   Testing   --------------------\n",
      "Epoch 2/20 | loss:0.03540\n",
      "=====================================================\n",
      "CPU RAM Free: 1.4 GB\n",
      "GPU 0 ... Mem Free: 3386MB / 8192MB | Utilization  57%\n",
      "=====================================================\n",
      "Epoch 3/20 | Step 100/782 | loss:0.03441 time: 10.0s\n",
      "Epoch 3/20 | Step 200/782 | loss:0.03446 time: 9.9s\n",
      "Epoch 3/20 | Step 300/782 | loss:0.03469 time: 9.8s\n",
      "Epoch 3/20 | Step 400/782 | loss:0.03468 time: 9.8s\n",
      "Epoch 3/20 | Step 500/782 | loss:0.03463 time: 9.8s\n",
      "Epoch 3/20 | Step 600/782 | loss:0.03470 time: 9.9s\n",
      "Epoch 3/20 | Step 700/782 | loss:0.03458 time: 9.9s\n",
      "Epoch 3/20 | Step 781/782 | loss:0.03461 time: 7.9s\n",
      "--------------------   Testing   --------------------\n",
      "Epoch 3/20 | loss:0.03517\n",
      "=====================================================\n",
      "CPU RAM Free: 1.4 GB\n",
      "GPU 0 ... Mem Free: 3386MB / 8192MB | Utilization  57%\n",
      "=====================================================\n",
      "Epoch 4/20 | Step 100/782 | loss:0.03415 time: 9.9s\n",
      "Epoch 4/20 | Step 200/782 | loss:0.03404 time: 9.8s\n",
      "Epoch 4/20 | Step 300/782 | loss:0.03396 time: 9.9s\n",
      "Epoch 4/20 | Step 400/782 | loss:0.03395 time: 9.8s\n",
      "Epoch 4/20 | Step 500/782 | loss:0.03398 time: 9.8s\n",
      "Epoch 4/20 | Step 600/782 | loss:0.03391 time: 9.8s\n",
      "Epoch 4/20 | Step 700/782 | loss:0.03386 time: 9.8s\n",
      "Epoch 4/20 | Step 781/782 | loss:0.03384 time: 7.9s\n",
      "--------------------   Testing   --------------------\n",
      "Epoch 4/20 | loss:0.03433\n",
      "=====================================================\n",
      "CPU RAM Free: 1.7 GB\n",
      "GPU 0 ... Mem Free: 3386MB / 8192MB | Utilization  57%\n",
      "=====================================================\n",
      "Epoch 5/20 | Step 100/782 | loss:0.03325 time: 10.0s\n",
      "Epoch 5/20 | Step 200/782 | loss:0.03324 time: 9.9s\n",
      "Epoch 5/20 | Step 300/782 | loss:0.03324 time: 9.9s\n",
      "Epoch 5/20 | Step 400/782 | loss:0.03332 time: 9.9s\n",
      "Epoch 5/20 | Step 500/782 | loss:0.03330 time: 9.8s\n",
      "Epoch 5/20 | Step 600/782 | loss:0.03328 time: 9.8s\n",
      "Epoch 5/20 | Step 700/782 | loss:0.03322 time: 9.8s\n",
      "Epoch 5/20 | Step 781/782 | loss:0.03323 time: 7.9s\n",
      "--------------------   Testing   --------------------\n",
      "Epoch 5/20 | loss:0.03517\n",
      "=====================================================\n",
      "CPU RAM Free: 1.7 GB\n",
      "GPU 0 ... Mem Free: 3386MB / 8192MB | Utilization  57%\n",
      "=====================================================\n",
      "Epoch 6/20 | Step 100/782 | loss:0.03276 time: 10.0s\n",
      "Epoch 6/20 | Step 200/782 | loss:0.03248 time: 9.9s\n",
      "Epoch 6/20 | Step 300/782 | loss:0.03251 time: 9.9s\n",
      "Epoch 6/20 | Step 400/782 | loss:0.03249 time: 9.9s\n",
      "Epoch 6/20 | Step 500/782 | loss:0.03261 time: 9.8s\n",
      "Epoch 6/20 | Step 600/782 | loss:0.03268 time: 9.8s\n",
      "Epoch 6/20 | Step 700/782 | loss:0.03268 time: 9.8s\n",
      "Epoch 6/20 | Step 781/782 | loss:0.03268 time: 7.8s\n",
      "--------------------   Testing   --------------------\n",
      "Epoch 6/20 | loss:0.03326\n",
      "=====================================================\n",
      "CPU RAM Free: 1.7 GB\n",
      "GPU 0 ... Mem Free: 3386MB / 8192MB | Utilization  57%\n",
      "=====================================================\n",
      "Epoch 7/20 | Step 100/782 | loss:0.03189 time: 9.8s\n",
      "Epoch 7/20 | Step 200/782 | loss:0.03198 time: 9.8s\n",
      "Epoch 7/20 | Step 300/782 | loss:0.03198 time: 9.9s\n",
      "Epoch 7/20 | Step 400/782 | loss:0.03203 time: 9.8s\n",
      "Epoch 7/20 | Step 500/782 | loss:0.03207 time: 9.8s\n",
      "Epoch 7/20 | Step 600/782 | loss:0.03206 time: 9.8s\n",
      "Epoch 7/20 | Step 700/782 | loss:0.03211 time: 9.9s\n",
      "Epoch 7/20 | Step 781/782 | loss:0.03211 time: 7.9s\n",
      "--------------------   Testing   --------------------\n",
      "Epoch 7/20 | loss:0.03344\n",
      "=====================================================\n",
      "CPU RAM Free: 1.7 GB\n",
      "GPU 0 ... Mem Free: 3386MB / 8192MB | Utilization  57%\n",
      "=====================================================\n",
      "Epoch 8/20 | Step 100/782 | loss:0.03145 time: 9.9s\n",
      "Epoch 8/20 | Step 200/782 | loss:0.03153 time: 9.8s\n",
      "Epoch 8/20 | Step 300/782 | loss:0.03149 time: 9.8s\n",
      "Epoch 8/20 | Step 400/782 | loss:0.03152 time: 9.8s\n",
      "Epoch 8/20 | Step 500/782 | loss:0.03158 time: 9.8s\n",
      "Epoch 8/20 | Step 600/782 | loss:0.03163 time: 9.8s\n",
      "Epoch 8/20 | Step 700/782 | loss:0.03160 time: 9.9s\n",
      "Epoch 8/20 | Step 781/782 | loss:0.03161 time: 7.9s\n",
      "--------------------   Testing   --------------------\n",
      "Epoch 8/20 | loss:0.03360\n",
      "=====================================================\n",
      "CPU RAM Free: 1.5 GB\n",
      "GPU 0 ... Mem Free: 3386MB / 8192MB | Utilization  57%\n",
      "=====================================================\n",
      "Epoch 9/20 | Step 100/782 | loss:0.03085 time: 10.0s\n",
      "Epoch 9/20 | Step 200/782 | loss:0.03108 time: 9.8s\n",
      "Epoch 9/20 | Step 300/782 | loss:0.03113 time: 9.8s\n",
      "Epoch 9/20 | Step 400/782 | loss:0.03109 time: 9.8s\n",
      "Epoch 9/20 | Step 500/782 | loss:0.03113 time: 9.8s\n",
      "Epoch 9/20 | Step 600/782 | loss:0.03120 time: 9.8s\n",
      "Epoch 9/20 | Step 700/782 | loss:0.03117 time: 9.8s\n",
      "Epoch 9/20 | Step 781/782 | loss:0.03119 time: 7.9s\n",
      "--------------------   Testing   --------------------\n",
      "Epoch 9/20 | loss:0.03306\n",
      "=====================================================\n",
      "CPU RAM Free: 1.7 GB\n",
      "GPU 0 ... Mem Free: 3386MB / 8192MB | Utilization  57%\n",
      "=====================================================\n",
      "Epoch 10/20 | Step 100/782 | loss:0.03060 time: 9.9s\n",
      "Epoch 10/20 | Step 200/782 | loss:0.03063 time: 9.8s\n",
      "Epoch 10/20 | Step 300/782 | loss:0.03072 time: 9.8s\n",
      "Epoch 10/20 | Step 400/782 | loss:0.03074 time: 9.8s\n",
      "Epoch 10/20 | Step 500/782 | loss:0.03072 time: 9.9s\n",
      "Epoch 10/20 | Step 600/782 | loss:0.03077 time: 9.9s\n",
      "Epoch 10/20 | Step 700/782 | loss:0.03078 time: 9.8s\n",
      "Epoch 10/20 | Step 781/782 | loss:0.03080 time: 7.9s\n",
      "--------------------   Testing   --------------------\n",
      "Epoch 10/20 | loss:0.03262\n",
      "=====================================================\n",
      "CPU RAM Free: 1.7 GB\n",
      "GPU 0 ... Mem Free: 3386MB / 8192MB | Utilization  57%\n",
      "=====================================================\n",
      "Epoch 11/20 | Step 100/782 | loss:0.03023 time: 10.0s\n",
      "Epoch 11/20 | Step 200/782 | loss:0.03023 time: 9.9s\n",
      "Epoch 11/20 | Step 300/782 | loss:0.03019 time: 9.8s\n",
      "Epoch 11/20 | Step 400/782 | loss:0.03023 time: 9.8s\n",
      "Epoch 11/20 | Step 500/782 | loss:0.03032 time: 9.8s\n",
      "Epoch 11/20 | Step 600/782 | loss:0.03030 time: 9.9s\n",
      "Epoch 11/20 | Step 700/782 | loss:0.03035 time: 9.9s\n",
      "Epoch 11/20 | Step 781/782 | loss:0.03041 time: 8.0s\n",
      "--------------------   Testing   --------------------\n",
      "Epoch 11/20 | loss:0.03263\n",
      "=====================================================\n",
      "CPU RAM Free: 1.6 GB\n",
      "GPU 0 ... Mem Free: 3386MB / 8192MB | Utilization  57%\n",
      "=====================================================\n",
      "Epoch 12/20 | Step 100/782 | loss:0.02992 time: 10.0s\n",
      "Epoch 12/20 | Step 200/782 | loss:0.02977 time: 9.9s\n",
      "Epoch 12/20 | Step 300/782 | loss:0.02979 time: 9.8s\n",
      "Epoch 12/20 | Step 400/782 | loss:0.02987 time: 9.8s\n",
      "Epoch 12/20 | Step 500/782 | loss:0.02993 time: 9.8s\n",
      "Epoch 12/20 | Step 600/782 | loss:0.02996 time: 9.8s\n",
      "Epoch 12/20 | Step 700/782 | loss:0.02998 time: 9.8s\n",
      "Epoch 12/20 | Step 781/782 | loss:0.02998 time: 7.9s\n",
      "--------------------   Testing   --------------------\n",
      "Epoch 12/20 | loss:0.03286\n",
      "=====================================================\n",
      "CPU RAM Free: 1.7 GB\n",
      "GPU 0 ... Mem Free: 3386MB / 8192MB | Utilization  57%\n",
      "=====================================================\n",
      "Epoch 13/20 | Step 100/782 | loss:0.02941 time: 9.9s\n",
      "Epoch 13/20 | Step 200/782 | loss:0.02943 time: 9.8s\n",
      "Epoch 13/20 | Step 300/782 | loss:0.02951 time: 9.8s\n",
      "Epoch 13/20 | Step 400/782 | loss:0.02957 time: 9.8s\n",
      "Epoch 13/20 | Step 500/782 | loss:0.02961 time: 9.8s\n",
      "Epoch 13/20 | Step 600/782 | loss:0.02960 time: 9.8s\n",
      "Epoch 13/20 | Step 700/782 | loss:0.02958 time: 9.8s\n",
      "Epoch 13/20 | Step 781/782 | loss:0.02957 time: 7.9s\n",
      "--------------------   Testing   --------------------\n",
      "Epoch 13/20 | loss:0.03243\n",
      "=====================================================\n",
      "CPU RAM Free: 1.7 GB\n",
      "GPU 0 ... Mem Free: 3386MB / 8192MB | Utilization  57%\n",
      "=====================================================\n",
      "Epoch 14/20 | Step 100/782 | loss:0.02917 time: 9.9s\n",
      "Epoch 14/20 | Step 200/782 | loss:0.02915 time: 9.9s\n",
      "Epoch 14/20 | Step 300/782 | loss:0.02932 time: 9.9s\n",
      "Epoch 14/20 | Step 400/782 | loss:0.02930 time: 9.8s\n",
      "Epoch 14/20 | Step 500/782 | loss:0.02930 time: 9.8s\n",
      "Epoch 14/20 | Step 600/782 | loss:0.02928 time: 9.9s\n",
      "Epoch 14/20 | Step 700/782 | loss:0.02930 time: 9.9s\n",
      "Epoch 14/20 | Step 781/782 | loss:0.02932 time: 7.9s\n",
      "--------------------   Testing   --------------------\n",
      "Epoch 14/20 | loss:0.03241\n",
      "=====================================================\n",
      "CPU RAM Free: 1.6 GB\n",
      "GPU 0 ... Mem Free: 3386MB / 8192MB | Utilization  57%\n",
      "=====================================================\n",
      "Epoch 15/20 | Step 100/782 | loss:0.02872 time: 9.9s\n",
      "Epoch 15/20 | Step 200/782 | loss:0.02862 time: 9.8s\n",
      "Epoch 15/20 | Step 300/782 | loss:0.02870 time: 9.8s\n",
      "Epoch 15/20 | Step 400/782 | loss:0.02873 time: 9.8s\n",
      "Epoch 15/20 | Step 500/782 | loss:0.02882 time: 10.1s\n",
      "Epoch 15/20 | Step 600/782 | loss:0.02884 time: 9.9s\n",
      "Epoch 15/20 | Step 700/782 | loss:0.02885 time: 9.8s\n",
      "Epoch 15/20 | Step 781/782 | loss:0.02889 time: 7.9s\n",
      "--------------------   Testing   --------------------\n",
      "Epoch 15/20 | loss:0.03235\n",
      "=====================================================\n",
      "CPU RAM Free: 1.5 GB\n",
      "GPU 0 ... Mem Free: 3386MB / 8192MB | Utilization  57%\n",
      "=====================================================\n",
      "Epoch 16/20 | Step 100/782 | loss:0.02846 time: 10.0s\n",
      "Epoch 16/20 | Step 200/782 | loss:0.02855 time: 9.8s\n",
      "Epoch 16/20 | Step 300/782 | loss:0.02853 time: 9.8s\n",
      "Epoch 16/20 | Step 400/782 | loss:0.02931 time: 9.8s\n",
      "Epoch 16/20 | Step 500/782 | loss:0.02980 time: 9.8s\n",
      "Epoch 16/20 | Step 600/782 | loss:0.02986 time: 9.8s\n",
      "Epoch 16/20 | Step 700/782 | loss:0.02979 time: 9.8s\n",
      "Epoch 16/20 | Step 781/782 | loss:0.02977 time: 7.8s\n",
      "--------------------   Testing   --------------------\n",
      "Epoch 16/20 | loss:0.03260\n",
      "=====================================================\n",
      "CPU RAM Free: 1.7 GB\n",
      "GPU 0 ... Mem Free: 3386MB / 8192MB | Utilization  57%\n",
      "=====================================================\n",
      "Epoch 17/20 | Step 100/782 | loss:0.02860 time: 9.9s\n",
      "Epoch 17/20 | Step 200/782 | loss:0.02855 time: 9.7s\n",
      "Epoch 17/20 | Step 300/782 | loss:0.02854 time: 9.7s\n",
      "Epoch 17/20 | Step 400/782 | loss:0.02847 time: 9.8s\n",
      "Epoch 17/20 | Step 500/782 | loss:0.02853 time: 9.8s\n",
      "Epoch 17/20 | Step 600/782 | loss:0.02853 time: 9.8s\n",
      "Epoch 17/20 | Step 700/782 | loss:0.02854 time: 9.8s\n",
      "Epoch 17/20 | Step 781/782 | loss:0.02855 time: 7.9s\n",
      "--------------------   Testing   --------------------\n",
      "Epoch 17/20 | loss:0.03244\n",
      "=====================================================\n",
      "CPU RAM Free: 1.6 GB\n",
      "GPU 0 ... Mem Free: 3386MB / 8192MB | Utilization  57%\n",
      "=====================================================\n",
      "Epoch 18/20 | Step 100/782 | loss:0.02786 time: 9.9s\n",
      "Epoch 18/20 | Step 200/782 | loss:0.02790 time: 9.7s\n",
      "Epoch 18/20 | Step 300/782 | loss:0.02782 time: 9.7s\n",
      "Epoch 18/20 | Step 400/782 | loss:0.02780 time: 9.8s\n",
      "Epoch 18/20 | Step 500/782 | loss:0.02784 time: 9.8s\n",
      "Epoch 18/20 | Step 600/782 | loss:0.02794 time: 9.7s\n",
      "Epoch 18/20 | Step 700/782 | loss:0.02796 time: 9.7s\n",
      "Epoch 18/20 | Step 781/782 | loss:0.02799 time: 7.8s\n",
      "--------------------   Testing   --------------------\n",
      "Epoch 18/20 | loss:0.03212\n",
      "=====================================================\n",
      "CPU RAM Free: 1.6 GB\n",
      "GPU 0 ... Mem Free: 3386MB / 8192MB | Utilization  57%\n",
      "=====================================================\n",
      "Epoch 19/20 | Step 100/782 | loss:0.02740 time: 9.9s\n",
      "Epoch 19/20 | Step 200/782 | loss:0.02760 time: 9.8s\n",
      "Epoch 19/20 | Step 300/782 | loss:0.02757 time: 9.7s\n",
      "Epoch 19/20 | Step 400/782 | loss:0.02768 time: 9.7s\n",
      "Epoch 19/20 | Step 500/782 | loss:0.02766 time: 9.7s\n",
      "Epoch 19/20 | Step 600/782 | loss:0.02767 time: 9.7s\n",
      "Epoch 19/20 | Step 700/782 | loss:0.02769 time: 9.8s\n",
      "Epoch 19/20 | Step 781/782 | loss:0.02767 time: 7.9s\n",
      "--------------------   Testing   --------------------\n",
      "Epoch 19/20 | loss:0.03229\n",
      "=====================================================\n",
      "CPU RAM Free: 1.7 GB\n",
      "GPU 0 ... Mem Free: 3386MB / 8192MB | Utilization  57%\n",
      "=====================================================\n"
     ]
    }
   ],
   "source": [
    "batch_size = 512\n",
    "device = torch.device('cuda')\n",
    "max_epochs = 20\n",
    "lr = 0.001\n",
    "\n",
    "decoder_model = Decoder()\n",
    "\n",
    "train_set_decoder = ZipDataset(train_set, train_set_latent_coords)\n",
    "test_set_decoder = ZipDataset(test_set, test_set_latent_coords)\n",
    "\n",
    "train_dataloader_decoder = torch.utils.data.DataLoader(train_set_decoder, batch_size=64, shuffle=True)\n",
    "test_dataloader_decoder = torch.utils.data.DataLoader(test_set_decoder, batch_size=64, shuffle=False)\n",
    "\n",
    "optimizer = torch.optim.Adam(decoder_model.parameters(), lr=lr)\n",
    "\n",
    "train(decoder_model, (train_dataloader_decoder, test_dataloader_decoder), optimizer,\n",
    "      device=device, max_epochs=max_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(decoder_model, 'decoder_model_32.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images_by_category(dataset, category):\n",
    "    category_indices = [i for i, label in enumerate(dataset.targets) if label == category]\n",
    "    images = [dataset[i][0] for i in category_indices]\n",
    "    return images\n",
    "\n",
    "# Revert the transformations in reverse order\n",
    "reverted_tf = tf.Compose([\n",
    "    # tf.Normalize((-0.485 / 0.229, -0.456 / 0.224, -0.406 / 0.225), (1 / 0.229, 1 / 0.224, 1 / 0.225)),\n",
    "    # tf.Normalize((0, 0, 0), (1, 1, 1)),  # Unnormalize the tensor\n",
    "    tf.ConvertImageDtype(torch.uint8),\n",
    "    tf.ToPILImage(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    i = 5\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    output = decoder_model(test_set_latent_coords[i].reshape(1,-1).to(device))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(reverted_tf(output.squeeze()))\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(reverted_tf(test_set[i][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add perceptual loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_latent_model_tf = tf.Compose([\n",
    "    tf.Resize((224, 224)),#, interpolation=torchvision.transforms.InterpolationMode.BICUBIC),\n",
    "    tf.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_perceptual_loss(model, transform):\n",
    "    def perceptual_loss(imgs, latent_coords):\n",
    "        return nn.MSELoss().to(device)(model(transform(imgs)), latent_coords)\n",
    "    return perceptual_loss\n",
    "\n",
    "def train(model, dataloaders, optimizer, **kwargs):\n",
    "    train_loader, test_loader = dataloaders\n",
    "    device = kwargs['device']\n",
    "    mse_loss = nn.MSELoss().to(device)\n",
    "    perceptual_loss = get_perceptual_loss(latent_code_model, to_latent_model_tf)\n",
    "    model = model.to(device)\n",
    "    mse_weight, perceptual_weight = kwargs['weights']\n",
    "    perceptual_weight_decay = kwargs['perceptual_weight_decay']\n",
    "    \n",
    "    for epoch in range(kwargs['max_epochs']):\n",
    "        ########  Train  ########\n",
    "        loss_list = []\n",
    "        model.train()\n",
    "        last_time = time.time()\n",
    "        for local_step, (images, latent_coords, labels) in enumerate(train_loader):\n",
    "            step = epoch * len(train_loader) + local_step\n",
    "            images, latent_coords, labels = images.to(device), latent_coords.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(latent_coords)\n",
    "            # print(torch.max(outputs), torch.min(outputs))\n",
    "            # print(outputs.shape)\n",
    "            l = mse_weights * mse_loss(outputs, images) + perceptual_weight * perceptual_loss(outputs, latent_coords)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # log\n",
    "            loss_list.append(l.detach().cpu().item())\n",
    "            if (local_step % 100 == 0 and local_step != 0) or local_step == len(train_loader) - 1:\n",
    "                print(\"Epoch {}/{} | Step {}/{} | loss:{:.5f} time: {:.1f}s\".format(\n",
    "                    epoch, kwargs['max_epochs'], local_step, len(train_loader),\n",
    "                    sum(loss_list)/len(loss_list),\n",
    "                    time.time() - last_time\n",
    "                ))\n",
    "                last_time = time.time()\n",
    "        ########  Test  ########\n",
    "        loss_list = []\n",
    "        print(\"-\"*20 + \"   Testing   \" + \"-\"*20)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for local_step, (images, latent_coords, labels) in enumerate(test_loader):\n",
    "                images, latent_coords, labels = images.to(device), latent_coords.to(device), labels.to(device)\n",
    "                outputs = model(latent_coords)\n",
    "                l = loss(outputs, images)\n",
    "                loss_list.append(l.cpu().item())\n",
    "            # log\n",
    "            print(\"Epoch {}/{} | loss:{:.5f}\".format(\n",
    "                epoch, kwargs['max_epochs'],\n",
    "                sum(loss_list)/len(loss_list)\n",
    "            ))\n",
    "        print(\"=\" * 53)\n",
    "        mem_report()\n",
    "        print(\"=\" * 53)\n",
    "        perceptual_weight = max(0, perceptual_weight - perceptual_weight_decay)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "device = torch.device('cuda')\n",
    "max_epochs = 20\n",
    "lr = 0.001\n",
    "weights = [1, 1]\n",
    "perceptual_weight_decay = 0.01\n",
    "\n",
    "decoder_model = Decoder()\n",
    "\n",
    "train_set_decoder = ZipDataset(train_set, train_set_latent_coords)\n",
    "test_set_decoder = ZipDataset(test_set, test_set_latent_coords)\n",
    "\n",
    "train_dataloader_decoder = torch.utils.data.DataLoader(train_set_decoder, batch_size=64, shuffle=True)\n",
    "test_dataloader_decoder = torch.utils.data.DataLoader(test_set_decoder, batch_size=64, shuffle=False)\n",
    "\n",
    "optimizer = torch.optim.Adam(decoder_model.parameters(), lr=lr)\n",
    "\n",
    "train(decoder_model, (train_dataloader_decoder, test_dataloader_decoder), optimizer,\n",
    "      device=device, max_epochs=max_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(decoder_model, 'decoder_model_32_with_perceptual.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
